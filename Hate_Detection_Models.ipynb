{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import classification_report\n",
    "from keras import layers, models, optimizers\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 2 labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speech_data = pd.read_csv(\".csv\")\n",
    "\n",
    "# split the dataset into training and testing datasets \n",
    "x_train, x_test, y_train, y_test = train_test_split(speech_data['a'], speech_data['b'], test_size=0.3, random_state=1)\n",
    "\n",
    "\n",
    "# create a count vectorizer object \n",
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(speech_data['a'])\n",
    "\n",
    "# transform the training and testing data using count vectorizer object\n",
    "x_train_count =  cv.transform(x_train)\n",
    "x_test_count =  cv.transform(x_test)\n",
    "\n",
    "tfidf_tr = TfidfTransformer()\n",
    "x_train_count_tfidf = tfidf_tr.fit_transform(x_train_count)\n",
    "x_test_count_tfidf = tfidf_tr.transform(x_test_count)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tv_ngram = TfidfVectorizer(ngram_range=(1,2))\n",
    "tv_ngram.fit(speech_data['a'])\n",
    "x_train_tfidf_ngram =  tv_ngram.transform(x_train)\n",
    "x_test_tfidf_ngram =  tv_ngram.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifierModel(classifier, Xtrain, Ytrain, Xtest):\n",
    "    classifier.fit(Xtrain, Ytrain)\n",
    "    predictions = classifier.predict(Xtest)\n",
    "    print(\"\\nAccuracy : \", accuracy_score(predictions, y_test))\n",
    "    \n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNaive Bayes with Count Vectors: \")\n",
    "classifierModel(MultinomialNB(), x_train_count, y_train, x_test_count)\n",
    "\n",
    "print(\"\\nNaive Bayes with Count Vectors + TF-IDF: \")\n",
    "classifierModel(MultinomialNB(), x_train_count_tfidf, y_train, x_test_count_tfidf)\n",
    "\n",
    "print(\"\\nNaive Bayes with N-Gram Vectors: \")\n",
    "classifierModel(MultinomialNB(), x_train_tfidf_ngram, y_train, x_test_tfidf_ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLinearSVM with Count Vectors: \")\n",
    "classifierModel(SVC(kernel='linear'), x_train_count, y_train, x_test_count)\n",
    "\n",
    "print(\"\\nLinearSVM with Count Vectors + TF-IDF: \")\n",
    "classifierModel(SVC(kernel='linear'), x_train_count_tfidf, y_train, x_test_count_tfidf)\n",
    "\n",
    "print(\"\\nLinearSVM with N-Gram Vectors: \")\n",
    "classifierModel(SVC(kernel='linear'), x_train_tfidf_ngram, y_train, x_test_tfidf_ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRandom Forrest Classifier with Count Vectors: \")\n",
    "classifierModel(RandomForestClassifier(random_state=40,n_estimators=1024), x_train_count, y_train, x_test_count)\n",
    "\n",
    "print(\"\\nRandom Forrest Classifier with Count Vectors + TF-IDF: \")\n",
    "classifierModel(RandomForestClassifier(random_state=40,n_estimators=1024), x_train_count_tfidf, y_train, x_test_count_tfidf)\n",
    "\n",
    "print(\"\\nRandom Forrest Classifier with N-Gram Vectors: \")\n",
    "classifierModel(RandomForestClassifier(random_state=40,n_estimators=1024), x_train_tfidf_ngram, y_train, x_test_tfidf_ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnnModel(Xtrain, Ytrain, Xtest):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(1000, 64),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(Xtrain, Ytrain, batch_size=30, epochs=10)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(Xtest, y_test)\n",
    "    print(\"\\nAccuracy : \",test_acc)\n",
    "    \n",
    "    predictions = model.predict(Xtest).ravel()\n",
    "    \n",
    "    target_names = ['class 0', 'class 1']\n",
    "    print(classification_report(y_test, predictions.round(), target_names=target_names)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRNN with Count Vectors: \")\n",
    "rnnModel(x_train_count, y_train, x_test_count)\n",
    "\n",
    "print(\"\\nRNN with  Count Vectors + TF-IDF: \")\n",
    "rnnModel(x_train_count_tfidf, y_train, x_test_count_tfidf)\n",
    "\n",
    "print(\"\\nRNN with N-Gram Vectors: \")\n",
    "rnnModel(x_train_tfidf_ngram, y_train, x_test_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For 3 Labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speech = pd.read_csv(\".csv\")\n",
    "\n",
    "# split the dataset into training and testing datasets \n",
    "x_train, x_test, y_train, y_test = train_test_split(speech['a'], speech['b'], test_size=0.3, random_state=1)\n",
    "\n",
    "# create a count vectorizer object \n",
    "cv = CountVectorizer(stop_words='english')\n",
    "cv.fit(speech['a'])\n",
    "\n",
    "# transform the training and testing data using count vectorizer object\n",
    "x_train_count =  cv.transform(x_train)\n",
    "x_test_count =  cv.transform(x_test)\n",
    "\n",
    "tfidf_tr = TfidfTransformer()\n",
    "x_train_count_tfidf = tfidf_tr.fit_transform(x_train_count)\n",
    "x_test_count_tfidf = tfidf_tr.transform(x_test_count)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tv_ngram = TfidfVectorizer(ngram_range=(1,2))\n",
    "tv_ngram.fit(speech['a'])\n",
    "x_train_tfidf_ngram =  tv_ngram.transform(x_train)\n",
    "x_test_tfidf_ngram =  tv_ngram.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifierModel(classifier, Xtrain, Ytrain, Xtest):\n",
    "    classifier.fit(Xtrain, Ytrain)\n",
    "    predictions = classifier.predict(Xtest)\n",
    "    print(\"\\nAccuracy : \", accuracy_score(predictions, y_test))\n",
    "    \n",
    "    target_names = ['class 0', 'class 1', 'class 2']\n",
    "    print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNaive Bayes with Count Vectors: \")\n",
    "classifierModel(MultinomialNB(), x_train_count, y_train, x_test_count)\n",
    "\n",
    "print(\"\\nNaive Bayes with Count Vectors + TF-IDF: \")\n",
    "classifierModel(MultinomialNB(), x_train_count_tfidf, y_train, x_test_count_tfidf)\n",
    "\n",
    "print(\"\\nNaive Bayes with N-Gram Vectors: \")\n",
    "classifierModel(MultinomialNB(), x_train_tfidf_ngram, y_train, x_test_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLinearSVM with Count Vectors: \")\n",
    "classifierModel(LinearSVC(), x_train_count, y_train, x_test_count)\n",
    "\n",
    "print(\"\\nLinearSVM with Count Vectors + TF-IDF: \")\n",
    "classifierModel(LinearSVC(), x_train_count_tfidf, y_train, x_test_count_tfidf)\n",
    "\n",
    "print(\"\\nLinearSVM with N-Gram Vectors: \")\n",
    "classifierModel(LinearSVC(), x_train_tfidf_ngram, y_train, x_test_tfidf_ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLinearSVM with Count Vectors: \")\n",
    "classifierModel(SVC(kernel='linear'), x_train_count, y_train, x_test_count)\n",
    "\n",
    "print(\"\\nLinearSVM with Count Vectors + TF-IDF: \")\n",
    "classifierModel(SVC(kernel='linear'), x_train_count_tfidf, y_train, x_test_count_tfidf)\n",
    "\n",
    "print(\"\\nLinearSVM with N-Gram Vectors: \")\n",
    "classifierModel(SVC(kernel='linear'), x_train_tfidf_ngram, y_train, x_test_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRandom Forrest Classifier with Count Vectors: \")\n",
    "classifierModel(RandomForestClassifier(random_state=40,n_estimators=1024), x_train_count, y_train, x_test_count)\n",
    "\n",
    "print(\"\\nRandom Forrest Classifier with Count Vectors + TF-IDF: \")\n",
    "classifierModel(RandomForestClassifier(random_state=40,n_estimators=1024), x_train_count_tfidf, y_train, x_test_count_tfidf)\n",
    "\n",
    "print(\"\\nRandom Forrest Classifier with N-Gram Vectors: \")\n",
    "classifierModel(RandomForestClassifier(random_state=40,n_estimators=1024), x_train_tfidf_ngram, y_train, x_test_tfidf_ngram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnnModel(Xtrain, Ytrain, Xtest):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(1000, 64),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(10)),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(Xtrain, Ytrain, batch_size=30, epochs=10)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(Xtest, y_test)\n",
    "    print(\"\\nAccuracy : \",test_acc)\n",
    "    \n",
    "    predictions = model.predict(Xtest)\n",
    "    \n",
    "    target_names = ['class 0', 'class 1', 'class 2']\n",
    "    print(classification_report(y_test, predictions.round(), target_names=target_names)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRNN with Count Vectors: \")\n",
    "rnnModel(x_train_count, y_train, x_test_count)\n",
    "\n",
    "print(\"\\nRNN with  Count Vectors + TF-IDF: \")\n",
    "rnnModel(x_train_count_tfidf, y_train, x_test_count_tfidf)\n",
    "\n",
    "print(\"\\nRNN with N-Gram Vectors: \")\n",
    "rnnModel(x_train_tfidf_ngram, y_train, x_test_tfidf_ngram)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
